# HappyWhale 

## 2022/04/08

å®Ÿé¨“ç’°å¢ƒã‚’ä½œã‚‹ã€‚

Detic + Segmentation ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã–ã£ã¨è¦‹ã‚Œã‚‹ã‚³ãƒ¼ãƒ‰ã§ããŸã€‚
https://www.kaggle.com/code/saki205/explore-segmentation-datset/notebook?scriptVersionId=92428272

ç™½é»’ã ã¨ã†ã¾ãã„ã£ã¦ãªã„ã‚„ã¤ã‚„ã€æ–‡å­—ãŒå…¥ã£ã¦ã‚‹ã¨ã†ã¾ãã„ã£ã¦ãªã„ã‚„ã¤ãŒå¤šã„å°è±¡ã€‚

![image](https://user-images.githubusercontent.com/48637189/162384692-8c89bb1a-bdcf-490d-8a71-7c0d07f3cb02.png)

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å¼·ãã™ã‚‹å‡¦ç†ã‚’ã—ã¦segmentationã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ãŸãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å‡ºç¾è©¦ã—ã¦ã¿ã‚‹ã€‚

https://www.kaggle.com/code/leoooo333/background-remove-tutorial

tfrecords + èƒŒæ™¯ã‚’æ¶ˆã—ãŸã‚„ã¤ã‚’ã©ã†ã™ã‚‹ã‹ãƒ¼ï¼èƒŒæ™¯ã‚’æ¶ˆã—ãŸã‚‚ã®ã‚‚TFRecordã«ã™ã‚‹ã€‚

https://www.kaggle.com/code/saki205/effv2-l-backfin-embeddings-ensemble-white
ã“ã‚Œã®ã‚³ãƒ¼ãƒ‰ç²¾èª­ä¸­ã€‚å­¦ç¿’ã—ã¦ã‚‹ã®ã‹æ—¢å­˜ã®å­¦ç¿’weightã‚’èª­ã¿è¾¼ã‚“ã§ã‚‹ã®ã‹ã‚ˆãåˆ†ã‹ã‚‰ãšã€è©°ã¾ã£ãŸã€‚



## 2022/04/07

Detic + Segmentation ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®Œæˆ
https://www.kaggle.com/datasets/saki205/deticsegmentation

ã†ã¾ãã§ããšå‡ºåŠ›ã™ã‚‰ã§ãã¦ãªã„ã‚‚ã®ã‚‚ã‚ã‚‹ã€‚è¦æ”¹å–„
ã†ã¾ãã§ããªã‹ã£ãŸã‚‚ã®ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã¾ã¨ã‚ãŸã€‚


half_trainã®ä½œæˆ
idãŒ10ä»¥ä¸Šã®ã‚‚ã®ã ã‘ã®train.csv

## 2022/04/06

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹ãŸã‚ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã‚’æ•´ãˆã¦ã„ã‚‹ãŒ
- Linux ä¸Šæ‰‹ãã„ã‹ãªã„ã€ã¨ã‚Šã‚ãˆãšãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ï¼ˆã‹ãªã‚Šæ™‚é–“ã‹ã‹ã£ã¦ã‚‹ï¼‰
- Windows ç«¯æœ«,Linuxç’°å¢ƒä½œæˆãªã†

## 2022/04/03
Segmentationã§èƒŒæ™¯åˆ‡ã‚Šå–ã£ã¦ä¿å­˜ã§ãã‚‹ã®ãŒã§ããŸ

å…¨ä½“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é©ç”¨ã—ã¦ä¿å­˜ã§ãã‚‹notebookã‚’ä½œã‚‹

https://www.kaggle.com/code/saki205/remove-background-salient-object-detection/data?scriptVersionId=91976209&select=task0.jpg

## 2022/04/02

([SHORTCUT] Competition logbook - updated everyday)[https://www.kaggle.com/competitions/happy-whale-and-dolphin/discussion/308991]

Remove Background ãŒã§ã¦Notebookå…¬é–‹ã•ã‚Œã¦ã‹ã‚‰83ã‚ãŸã‚Šã®ã‚¹ã‚³ã‚¢ãŒå¢—ãˆã¦ã‚‹ã€‚è¦ç¢ºèª
https://www.kaggle.com/code/remekkinas/remove-background-salient-object-detection/notebook


https://www.kaggle.com/c/happy-whale-and-dolphin/discussion/309214

çµæ§‹ç°¡å˜ã«å‹•ä½œç¢ºèªã§ãã‚‹ã€‚æ¬¡è©¦ã—ã¦ã¿ã‚‹ã€‚

## 2022/03/31

BaseLineç¢ºèªçµ‚ã‚ã‚Šã€‚

Rotateã—ãŸã‚‰ç²¾åº¦ä¸‹ãŒã£ãŸã€‚ã€‚ã€‚ãªã‚“ã§ã‚„

---

Grayscaleã«ã—ãŸã‚‰ãªã‚“ã‹ãƒ¡ãƒ¢ãƒªé£Ÿã„ã¾ãã£ã¦å‹•ã‹ã‚“ããªã£ãŸã€‚ã€‚
ç”»åƒã‚»ãƒƒãƒˆä½œã‚‹æ©Ÿæ§‹ã¨ã‹åˆ†ã‘ãŸã»ã†ãŒã„ã„ã‚“ã‹ãª
ã ã‹ã‚‰ã‚µã‚¤ã‚º640->128ã¾ã§å°ã•ãã—ã¦ã‚„ã£ã¦ã‚‹

TPUãŒã‚„ã£ã±åˆ¶é™ã‚ã‚‹ã—ã€ã‚¨ãƒãƒƒã‚¯ã‚‚æœ€ä½é™ã§ã‚ã‚‹ç¨‹åº¦ã®å›ã—æ–¹ã—ãŸæ–¹ãŒè‰¯ã•ã’ãªæ°—ãŒã—ã¦ããŸãªã€‚

ä½œæˆã—ãŸã€‚epoch 17,img 128
ã“ã‚Œã§è‰²ã€…ã¾ã‚ãã†

---

### Discussion ã¾ã¨ã‚

#### [cropped&resized(512x512) dataset using detic
](https://www.kaggle.com/competitions/happy-whale-and-dolphin/discussion/305503)

Deticã€€ã‚’ç”¨ã„ãŸã‚¯ãƒ­ãƒƒãƒ—ã®æ‰‹æ³•ã€‚å®Œç’§ã§ã¯ãªã„

#### [ğŸ§ Things to know before starting image preprocessing (https://www.kaggle.com/competitions/happy-whale-and-dolphin/discussion/308026)

ã©ã®ã‚ˆã†ãªç”»åƒãŒã‚ã‚‹ã‹ã®èª¬æ˜

#### [9 Computer Vision Tricks to Improve Performance
](https://www.kaggle.com/competitions/happy-whale-and-dolphin/discussion/310105)

ç”»åƒã‚³ãƒ³ãƒšã®å–ã‚Šçµ„ã¿æ–¹ã‚„é€²ã‚æ–¹çš„ãªã‚‚ã®

1. Start with Smaller Resolution


ä»Šå›ç”¨ã®åŠ å·¥ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¾ã¨ã‚


(Dataset Dataset Dataset)[https://www.kaggle.com/c/happy-whale-and-dolphin/discussion/309691]

2. Start with subsets of Data:
å°‘ãªã„ã‚¯ãƒ©ã‚¹æ•°ã‹ã‚‰å§‹ã‚ã‚‹ã€‚

3. Use FP16 or Half-Precision Training:
Who doesn't want up to 50% faster training?
NVIDIA GPUs have Tensor-Cores which offer huge speedups when using "Half-Precision" Tensors. I have written a more detailed blogÂ here, the short version is to try usingÂ fp_16Â training to observe speedups on any GPU (and TPU!)

4. Use TPUs:
TPUæ—©ãã¦ä¾¿åˆ©ã€ã‚³ã‚¢æ•°ã‚‚ï¼˜ã‚ã‚‹ã‹ã‚‰å¤§ããƒ‡ãƒ¼ã‚¿æ•°ã«ã‚‚ã‚¹ã‚±ãƒ¼ãƒ«ã§ãã‚‹ã€‚

Note: I have recently discovered Hugging Face Accelerate which claims to give you easy workflow on TPUs with PyTorch too

5. Progressive Resizing:

å­¦ç¿’ã™ã‚‹ç”»åƒã‚µã‚¤ã‚ºã‚’å¤‰ãˆã‚‹ã“ã¨ã§åæŸã‚’æ—©ãã™ã‚‹ã€‚

Chris Deotte has a fantasticÂ postÂ talking about CNN Input image sizes.Â ThisÂ blog teaches you how progressive resizing works in fastai. TL;DR:
* Train model on size: small
* Save weights and re-train model on larger image size
* Save weights again and re-train on final image sizes
This process allows much faster convergence and better performance


6. Experiment: Depthwise Convs instead of Regular Convs:

Depthwise Convolutions ã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ•°ãŒå°‘ãªãæ™®é€šã®ãŸãŸã¿è¾¼ã¿ã‚ˆã‚ŠåæŸãŒæ—©ã„ã€‚

I believe thisÂ conceptÂ was introduced in the MobileNet paper first and I saw it resurface in a recent discussion related to ConvNext architectures. Depthwise Convolutions have fewer filters and hence train faster.

See hereÂ for some tips on making it work in PyTorch



7. LR Scheduler:

å‹•çš„ã«å­¦ç¿’ç‡ãŒå¤‰åŒ–ã™ã‚‹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’ä½¿ãŠã†ã€‚

There are many schedulers that allow this: I would recommend usingÂ fastaiÂ and itsÂ fine_tune()Â orÂ fit_one_cycle()Â function. SeeÂ hereÂ for more details.



8. LR Warmup:
This one is in-line with the previous one:
From the paper,Â "Bag of Tricks", one of the ticks highlights using LR warmup.

å°ã•ã„å­¦ç¿’ç‡ã‹ã‚‰ã ã‚“ã ã‚“ä¸Šã’ã¦ã„ãã®ãŒè‰¯ã„ã€‚

9. Image Augmentations:

ã»ã‚“ã¨å°‘ã—ã®å¤‰åŒ–ã§ã‚‚ç²¾åº¦ã¯ä¸ŠãŒã‚‹ã€‚æ­£ã—ã„Augumentation ã‚’è¡ŒãŠã†ã€‚

Chris Deotte in his recentÂ CTDS interviewÂ shared some secrets. Qishen Ha, whose team had won the TF GBR competition also sharedÂ some tipsÂ of making these work

èƒŒæ™¯ã§ã¯ãªãã€ã‚¯ã‚¸ãƒ©ã‚’å­¦ã‚“ã§ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã‚ˆã†ã€‚

Bonus Tip #1: Use Timm or Tfimm:
TimmÂ andÂ Tfimm, the latter being a TF-port of the former is a fantastic resource! Ross, posts almost all the cutting edge model weights along withÂ extremelyÂ optimised training methods. I would highly recommend also spending time digging into their source code but at the least using the library is a solid suggestion for anyone working on CV problems
Bonus Tip #2: Use NGC Containers for Local training:
I understand many people are using Kaggle kernels and Colab for training. However, if you've invested in local hardware,Â RossÂ had taught in a thread on Twitter that theÂ NGC ContainersÂ for PyTorch are very optimised and offer speedups
I hope you find these helpful and also find some training or score boosts! :)
Happy Kaggling!


[Releasing my Dorsal Fin Dataset & Code
](https://www.kaggle.com/competitions/happy-whale-and-dolphin/discussion/310153)

å°¾ã³ã‚Œã ã‘ã‚’æŠœãã ã—ãŸç”»åƒã‚»ãƒƒãƒˆ

[Reduced Resolution Image Data (128 x 128, 256 x 256, 384 x 384) ğŸ‹
](https://www.kaggle.com/competitions/happy-whale-and-dolphin/discussion/304686)

ç”»åƒã®ã‚µã‚¤ã‚ºã‚’è½ã¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç´¹ä»‹

1. (128 x 128 dataset)Â https://www.kaggle.com/rdizzl3/jpeg-happywhale-128x128
2. (256 x 256 dataset)Â https://www.kaggle.com/rdizzl3/jpeg-happywhale-256x256
3. (384 x 384 dataset)Â https://www.kaggle.com/rdizzl3/jpeg-happywhale-384x384


[Previous Happywhale Competition Solutions
](https://www.kaggle.com/competitions/happy-whale-and-dolphin/discussion/304504)

å‰å›ã®HappyWhaleã®è§£æ³•


[7 More Computer Vision Tricks to Improve Score
](https://www.kaggle.com/competitions/happy-whale-and-dolphin/discussion/311211)


1. Test Time Augmentation (TTA):
ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®æ–¹ã«ã‚‚ãƒˆãƒ¬ã‚¤ãƒ³ã¨åŒã˜ç”»åƒå‡¦ç†ã‚’ã—ã‚ˆã†

2. Sequential Unfreezing while Transfer Learning:
I learned this trick during the fastai course. When we are performing transfer learning, our model has already captured a lot of information.
The initial layers (Layers close to inputs) retain more info about the structure of objects, etc and the latter layers (close to output) learn more about the dataset. We can envision our model to be grouped in layers like so:
Input(Group) -> HiddenSetEarly -> HiddenSetLater -> Output(Group)
When performing transfer learning, its usually a good idea to just train the last few layers and then unfreeze the earlier layersÂ sequentially

3. Differential Learning Rates:
Continuing with the previous point, another trick I learned via fastai:
The initial few layers need little to no re-training, so applying differential learning rates to a different group of CNN layers is a great idea:
Ex:â€¨Output(Group): Lr = 10e-3â€¨HiddenSetLater: LR = 0.5 * 10e-4â€¨Input(Group): Lr = 10e-5
This would make minimal changes to the initial layers and more changes to the head (output) layers making our model converge a bit faster

ç•°ãªã‚‹å±¤ã«ç•°ãªã‚‹å­¦ç¿’ç‡ã‚’å‰²ã‚Šå½“ã¦ãŸã£ã¦ã“ã¨ã‹ï¼Ÿ

4. PyTorch: use LazyLayers
Note: I learned this trick thanks to Datasaurus, please see his postÂ here

self.fc = nn.LazyLinear(self.cfg.target_size)
Note: This would otherwise beÂ self.fc = nn.Linear(self.n_features, self.cfg.target_size)
Once again, thanks Datasaurus for sharing this in his original post

5. Label Smoothing:
We have seen a lot of discussions in this competition about the funny images that exist in the dataset. This is not uncommon, ImageNet and many datasets themselves have many "mislabeled" images. The trick to helping here is using Label Smoothing.
ThisÂ is a good writeup about how it works. TL;DR: Adding noise to all labels helps our model generalize better


å¤‰ãªãƒ©ãƒ™ãƒªãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ã‚‚ã‚ã‚‹ã‹ã‚‰ã€è¨‚æ­£ã—ãŸã»ã†ãŒã„ã„ã€‚

6. Use GeM Pooling + ArcFace:
ã‚¢ãƒ³ãƒãƒ©ãƒ³ã‚¹ãªãƒ©ãƒ™ãƒ«ã®æ™‚ã«ã‚ˆãåŠ¹ãæ‰‹æ³•



7. PsuedoLabelling:
PsuedoLabelling involves a form of semi-supervised learning. Chris Deotte teaches this in his fantastic kernelÂ here

ä¿¡é ¼åº¦ã®é«˜ã„äºˆæ¸¬ã‚’ãƒ©ãƒ™ãƒ«ã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã“ã¨

Bonus Tip: Use SSDs for image datasets

ãƒ­ãƒ¼ã‚«ãƒ«ã§ä½œæ¥­ã—ã¦ã„ã‚‹ãªã‚‰ã°ã€ãƒ‡ãƒ¼ã‚¿ã¯SSDã«ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã€‚


(Duplicate names in species, can be merged together
)[https://www.kaggle.com/competitions/happy-whale-and-dolphin/discussion/304633]

ã“ã¨ãªã‚‹è¡¨è¨˜ãŒè¦‹ã¤ã‹ã£ãŸã¨ã„ã†ã“ã¨ã€‚

I observed that there are some duplicates in the species names
1. bottlenose_dolphin and bottlenose_dolpin
2. killer_whale and kiler_whale
On the safer side, there are no overlap of individual_id's between the different naming conventions.


(ğŸ”¥ DATASET - dorsal fins for all IDs without background ğŸ”¥
)[https://www.kaggle.com/competitions/happy-whale-and-dolphin/discussion/309214]

èƒŒæ™¯åˆ‡ã‚Šå–ã£ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä½¿ã£ã¦ã„ã‚‹ã€‚




## 2022/03/29

**ã‚ˆãå‡ºã¦ãã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¤ã„ã¦**
HappyWhaleSplitsï¼šindividual id ã‚’å…¨ã¦0 index ã«ç½®ãå¤‰ãˆãŸã€‚

https://www.kaggle.com/datasets/ks2019/happywhale-splits

TFRecordsï¼šä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å ´åˆã«ãã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åã‚ŠãŒå°‘ãªããªã‚‹ã‚ˆã†ã«trainã¨testã‚’åˆ†å‰²ã—ã¦ã„ã‚‹ã¿ãŸã„ã€‚å…·ä½“çš„ã«ã¯StratifiedKFoldã‚’ç”¨ã„ã¦ã„ã‚‹ã€‚(ä¸‹ç”»åƒ)

https://www.kaggle.com/ks2019/happywhale-tfrecordsã€€https://www.kaggle.com/ks2019/happywhale-tfrecords-v1


å‡¦ç†ã—ã¦ã„ã‚‹ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ï¼šhttps://www.kaggle.com/code/ks2019/happywhale-tfrecords/notebook

![image](https://user-images.githubusercontent.com/48637189/160507155-0c146ae3-37c1-4f5f-945b-07721b778159.png)

åˆ†å‰²ã®æ‰‹æ³•ã€€https://www.case-k.jp/entry/2021/02/14/155742#:~:text=StratifiedKFold,%E3%81%84%E3%82%8B%E3%81%93%E3%81%A8%E3%81%8C%E3%82%8F%E3%81%8B%E3%82%8A%E3%81%BE%E3%81%99%E3%80%82


å‹•ä½œç¢ºèªå®Œäº†
[Backfins ARCFace TPU Effnet
](https://www.kaggle.com/code/jpbremer/backfins-arcface-tpu-effnet/notebook)

äºŒã¤ç›®ãŒå¿…ãšnew_indivisualãªã®æ°—ã«ãªã‚‹ã€‚

---

## 2022/03/28
### 0.720_ğŸ³&ğŸ¬EFF_B5_640_Rotate https://www.kaggle.com/code/nghiahoangtrung/0-720-eff-b5-640-rotate/notebook
https://www.kaggle.com/code/jpbremer/backfins-arcface-tpu-effnet/notebook ãƒ™ãƒ¼ã‚¹ã«ãªã£ãŸã‚³ãƒ¼ãƒ‰

 (-10, 10 ) degreeå›è»¢ã™ã‚‹ã“ã¨ã§å¤§ããç²¾åº¦ã‚’å‘ä¸Šã•ã›ãŸã€€0.67->0.72

```
# Data augmentation function
def data_augment(posting_id, image, label_group, matches):

    ### CUTOUT
    if tf.random.uniform([])>0.5 and config.CUTOUT:
      N_CUTOUT = 6
      for cutouts in range(N_CUTOUT):
        if tf.random.uniform([])>0.5:
           DIM = config.IMAGE_SIZE
           CUTOUT_LENGTH = DIM//8
           x1 = tf.cast( tf.random.uniform([],0,DIM-CUTOUT_LENGTH),tf.int32)
           x2 = tf.cast( tf.random.uniform([],0,DIM-CUTOUT_LENGTH),tf.int32)
           filter_ = tf.concat([tf.zeros((x1,CUTOUT_LENGTH)),tf.ones((CUTOUT_LENGTH,CUTOUT_LENGTH)),tf.zeros((DIM-x1-CUTOUT_LENGTH,CUTOUT_LENGTH))],axis=0)
           filter_ = tf.concat([tf.zeros((DIM,x2)),filter_,tf.zeros((DIM,DIM-x2-CUTOUT_LENGTH))],axis=1)
           cutout = tf.reshape(1-filter_,(DIM,DIM,1))
           image = cutout*image

    image = tf.image.random_flip_left_right(image)
    # image = tf.image.random_flip_up_down(image)
#     degree = random.uniform(-10, 10)
#     image = tfa.image.rotate(image, degree * math.pi / 180)
    
    image = tf.image.random_hue(image, 0.01)
    image = tf.image.random_saturation(image, 0.70, 1.30)
    image = tf.image.random_contrast(image, 0.80, 1.20)
    image = tf.image.random_brightness(image, 0.10)
    return posting_id, image, label_group, matches
```



### Happywhale - Effnet B7 fork with Detic Training https://www.kaggle.com/code/aikhmelnytskyy/happywhale-effnet-b7-fork-with-detic-training/notebook

Backfins ARCFace TPU Effnet https://www.kaggle.com/code/jpbremer/backfins-arcface-tpu-effnet/notebook
ã¨ã®é•ã„ã‚’è¦‹ã¦ã„ã

**ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ãŒç•°ãªã‚‹**

å‰è€…
```
GCS_PATH = 'gs://kds-2f25b435592b59d6a2e92f82f0316665f6b69e4768d1296342746e85'  # Get GCS Path from kaggle notebook if GCS Path is expired
if not IS_COLAB:
    GCS_DS_PATH=KaggleDatasets().get_gcs_path('happywhale-tfrecords-bb')
    
train_files = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/happywhale-2022-train*.tfrec')))
test_files = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/happywhale-2022-test*.tfrec')))
print(GCS_PATH)
print(len(train_files),len(test_files),count_data_items(train_files),count_data_items(test_files))
```

å¾Œè€…
```
GCS_PATH = 'gs://kds-d916c3252bf3bc5b3500b904f05f51ce57c8df85221d11b7711bcda9'  # Get GCS Path from kaggle notebook if GCS Path is expired
if not IS_COLAB:
    GCS_PATH1 = KaggleDatasets().get_gcs_path('backfintfrecords')
    
train_files = np.sort(np.array(tf.io.gfile.glob(GCS_PATH1 + '/happywhale-2022-train*.tfrec')))
test_files = np.sort(np.array(tf.io.gfile.glob(GCS_PATH1 + '/happywhale-2022-test*.tfrec')))
print(GCS_PATH)
print(len(train_files),len(test_files),count_data_items(train_files),count_data_items(test_files))
```

å‰è€…ï¼šeffnetv1_b7

å¾Œè€…ï¼šeffnetv1_b5

çµè«–

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®é•ã„ã¨ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã®å·®ç•°

### Happywhale[0.679] https://www.kaggle.com/code/andrej0marinchenko/happywhale-0-679/notebook

ã‚ã‹ã‚‰ãªã„

### [D]Releasing my Dorsal Fin Dataset & Code https://www.kaggle.com/c/happy-whale-and-dolphin/discussion/310153

è£½ä½œè€…ã¯æ™‚é–“ãªãã¦å‚åŠ ã§ããªã„ã‹ã‚‰å¾Œæ‚”ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

Comment

Qã€€ãªã‚“ã§å°¾é°­ã ã‘ï¼Ÿä½“ã‚‚ä½¿ã£ãŸæ–¹ãŒã„ã„ã®ã§ã¯ï¼Ÿ

A ãƒ‡ãƒ¼ã‚¿ã«ã°ã‚‰ã¤ããŒå‡ºã‚‹ãŸã‚

Q "It includes bounding boxes for 4500 whales with a dorsal fin, not including beluge, southern right whale and gray whale."ã€€ã£ã¦ã‚ã‚‹ã‘ã©ãªã‚“ã§ä¸‰ç¨®é¡ã¯æ¡ç”¨ã—ã¦ã„ãªã„ï¼Ÿ

A ãã‚Œã‚‰ã¯å°¾é°­ãŒä»–ã®è€…ãŸã¡ã¨åŒã˜ã‚ˆã†ã«ã¤ã„ã¦ã„ãªã„ãŸã‚

ã“ã‚Œå‚ç…§ã€€https://www.kaggle.com/code/kwentar/what-about-species/notebook



**Object Detection**

It includes bounding boxes for 4500 whales with a dorsal fin, not including beluge, southern right whale and gray whale.
Please upvote the dataset if you are using it in your pipeline
Here it is:
https://www.kaggle.com/jpbremer/backfin-annotations



### âš¡ï¸ [EDA] âš¡ï¸ EDA + Visualization + Augmentation ğŸ”¥ğŸ”¥ https://www.kaggle.com/code/sahamed/eda-visualization-augmentation

ãƒ‡ãƒ¼ã‚¿æ•°ã‚„æå‡ºå½¢å¼ãªã©ãŒã‹ãªã‚Šè©³ã—ãæ›¸ã„ã¦ã‚ã‚Šã€ã¨ã¦ã‚‚å‚è€ƒã«ãªã‚‹ã€‚

```
bottlenose_dolphin           9664
beluga                       7443
humpback_whale               7392
blue_whale                   4830
false_killer_whale           3326
dusky_dolphin                3139
spinner_dolphin              1700
melon_headed_whale           1689
minke_whale                  1608
killer_whale                 1493
fin_whale                    1324
gray_whale                   1123
bottlenose_dolpin            1117
kiler_whale                   962
southern_right_whale          866
spotted_dolphin               490
sei_whale                     428
short_finned_pilot_whale      367
common_dolphin                347
cuviers_beaked_whale          341
pilot_whale                   262
long_finned_pilot_whale       238
white_sided_dolphin           229
brydes_whale                  154
pantropic_spotted_dolphin     145
globis                        116
commersons_dolphin             90
pygmy_killer_whale             76
rough_toothed_dolphin          60
frasiers_dolphin               14
Name: species, dtype: int64
```

ç¨®æ—ã”ã¨ã®åã‚Šã¯ã‹ãªã‚Šã‚ã‚‹ã€‚

**Data Cleaning**

Fixing Duplicate Labels
- bottlenose_dolpin -> bottlenose_dolphin
- kiler_whale -> killer_whale
- beluga -> beluga_whale


Changing Label due to extreme similarities


- globis & pilot_whale -> short_finned_pilot_whale


**Missing data**

None

**Top 5 least frequent individual**

ç”»åƒãŒä¸€æšã—ã‹ãªã„å€‹ä½“ã¯ç”»åƒã‚’è¤‡è£½ã™ã‚‹ã€‚

<img width="659" alt="image" src="https://user-images.githubusercontent.com/48637189/160413422-bd7178ab-2a57-4795-8e0d-0bab3136461a.png">


ç”»åƒãŒ5æšä»¥ä¸‹ã®å€‹ä½“ã¯40%ã‚‚ã„ã‚‹




## 2022/03/25
### [D] cropped&resized(512x512) dataset using detic https://www.kaggle.com/competitions/happy-whale-and-dolphin/discussion/305503

Cropped dataset with Detic

cocoa : small box size

detic : bigger box size

**How to create this dataset:**

1. Detect objects in the class of dolphins, whales, and marine life.
2. Select the largest bbox from the detection result and enlarge bbox by 1.2 times. then, crop&resize it.
3. If not found, just resize the image without cropping.

**Problem**
Since the model may predict smaller proposals with higher confidence, some detection results like the one in the image below are included.
If you are interested in false-positive result, please confirm csv file.

https://i.imgur.com/3cAFvvl.png![image](https://user-images.githubusercontent.com/48637189/160092868-c15c8d4e-cc40-4464-85f6-dacfca88c3e2.png)

Dataset link: https://www.kaggle.com/phalanx/whale2-cropped-dataset


**Comment**

Using this method in one kernel

https://www.kaggle.com/code/lextoumbourou/happywhale-effnet-b6-fork-with-detic-crop/notebook

### [D] ğŸ§ Things to know before starting image preprocessing https://www.kaggle.com/competitions/happy-whale-and-dolphin/discussion/308026

Overview of Datsets

- imgae_size : so various.
- night view 

https://i.imgur.com/5IWktBo.png![image](https://user-images.githubusercontent.com/48637189/160099035-ffcd6343-5486-49eb-8a5a-42fa1adc64fc.png)


-multiple indivisuals : more than two subjects
https://i.imgur.com/uQgnu1h.png![image](https://user-images.githubusercontent.com/48637189/160098641-0343a836-cdd0-4f40-8b1a-f456c1b7055c.png)

- landscape : Almost of landscape
https://i.imgur.com/Gt9F5nZ.png![image](https://user-images.githubusercontent.com/48637189/160098822-5516dead-b23c-49c5-8ab5-ea1f9e157b90.png)

- image annotations : some images have digital marking 
https://i.imgur.com/tQj1qxf.png![image](https://user-images.githubusercontent.com/48637189/160098895-48c09e41-431a-4722-a710-2abab6900cb5.png)

- image duplicates : some images are same
- lighting : sometimes the water can be greenish, sometimes bluish, sometimes pink (because of a sunset for example). 
- some onject : penguins and people, board
- ice : many pictures contain ice 

**Comments**

In some cases it is better to discard some images!

**Conclusion**

- Change RGB into B&W
- Can we use aditional data (Ice, Penguin, People)

---

## 2022/03/22

### simple ensemble of public best kernels
ç¾çŠ¶ãƒˆãƒƒãƒ—ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯è¦‹ã¦ã„ã
https://www.kaggle.com/code/yamsam/simple-ensemble-of-public-best-kernels
æœ‰åã©ã“ã‚ã‚’ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã—ã¦ã‚‹ã€‚

å…ƒã«ãªã£ã¦ã‚‹ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ä»¥ä¸‹ã®å››ã¤

- https://www.kaggle.com/aikhmelnytskyy/happywhale-arcface-baseline-eff7-tpu-768-inference

- https://www.kaggle.com/nghiahoangtrung/0-720-eff-b5-640-rotate

- https://www.kaggle.com/aikhmelnytskyy/happywhale-effnet-b7-fork-with-detic-training

- https://www.kaggle.com/andrej0marinchenko/happywhale-0-679




### happywhale_arcface_baseline_eff7_tpu_768_inference (https://www.kaggle.com/code/aikhmelnytskyy/happywhale-arcface-baseline-eff7-tpu-768-inference/notebook)
å…ƒã«ãªã£ãŸãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã€€https://www.kaggle.com/ks2019/happywhale-arcface-baseline-tpu

Model : EfficientNetB6

ä»Šã¾ã§ï¼šä¸€ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’one foldã§å­¦ç¿’ã•ã›ãŸã‚‚ã®ã ã‘ã‚’ä½¿ç”¨ã—ã¦ã„ãŸã€‚

ä»Šå›ã€€ï¼šäº”ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’åˆ¥ã€…ã«å­¦ç¿’ã•ã›ãŸã€‚-> **ã‚¹ã‚³ã‚¢5%ä¸ŠãŒã£ãŸ**


ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
- èƒŒé°­ã«åˆã‚ã›ã¦æ­£æ–¹å½¢ã«åˆ‡ã‚Šå–ã‚Š


# ArcMarginProductã‚’ä½¿ã†ã€ã‚ã¨ã§èª¿ã¹ã‚‹

Modelã®æ§‹é€ 
<img width="577" alt="image" src="https://user-images.githubusercontent.com/48637189/159396103-86ac750e-fc2b-49d1-afac-c2f3c2267bd3.png">

å­¦ç¿’ç‡ã¯ã‚ˆãè¦‹ã‚‹ã“ã®å½¢ã‚’ä½¿ã†ã€‚

<img width="455" alt="image" src="https://user-images.githubusercontent.com/48637189/159396455-5ba82a5c-fc45-4bc7-bd89-47f261bad203.png">

Better than median ã‚’ä½¿ã£ã¦ã‚‹ã€‚
https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/282735


äº‹å‰ã«å­¦ç¿’ã—ãŸäº”ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã‚‹ã€‚

ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯å­¦ç¿’ã‚’å›ã—ã¦ã„ãªã„ã€‚
https://www.kaggle.com/code/aikhmelnytskyy/happywhale-effnet-b7-fork-with-detic-training/notebook
å­¦ç¿’ã¯ã“ã®URL

é–¾å€¤ã‚’ã„ã‚ã„ã‚è©¦ã—æœ€é©ãªå€¤ã‚’æ±‚ã‚ã‚‹ã€‚

**Comment**
Q. TFRecordsã‹ã‚‰æ—¢ã«å‡¦ç†æ¸ˆã¿ã®Test Datasetã‚’å–å¾—ã—ã¦ãŸã‘ã©ã©ã†ã‚„ã£ã¦ã‚‹ã®ï¼Ÿ

A. Private datasetã«ã™ã§ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã‚‹ã€‚train ã®æ–¹ã§ã‹ãã«ã‚“ã—ã¦ã­ã€‚

Q. ã²ã¨ã¤ã®ç”»åƒã«äº”ã¤ã®äºˆæ¸¬ã‚’ã—ã¦ã‚‹ï¼Ÿ

A. ç•°ãªã‚‹foldã§å­¦ç¿’ã•ã›ãŸäº”ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®å¹³å‡å€¤ã‚’å–å¾—ã—ã¦ã‚‹ã€‚

ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã«ã¤ã„ã¦ã®Disscussion
https://www.kaggle.com/c/happy-whale-and-dolphin/discussion/310119

---

### [æ—¥æœ¬èª&ENG] HappyWhale effnetv2-m ã‚†ã£ãã‚Šå®Ÿæ³ [infer] https://www.kaggle.com/code/pixyz0130/eng-happywhale-effnetv2-m-infer

efficient-v2 ã‚’ä½¿ã†ã¨ãã¯TPUã‚’ä½¿ç”¨ã™ã‚‹ã€‚

https://www.kaggle.com/code/aikhmelnytskyy/happywhale-arcface-baseline-eff-net-kfold5-0-652/notebook
ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®efficient-v1ã‚’efficient-v2ã«å¤‰æ›´ã—ãŸã®ã¿

---

### HappyWhale ArcFace Baseline (TPU) https://www.kaggle.com/code/ks2019/happywhale-arcface-baseline-tpu

ã¯ã˜ã‚ã¦ArcFaceã‚’ç”¨ã„ãŸãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã€‚
ã‹ãªã‚Šå¤šãã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®å…ƒã«ãªã£ã¦ã„ã‚‹æ„Ÿã˜ã€‚

---

### [Pytorch] ArcFace + GeM Pooling Starter https://www.kaggle.com/code/debarshichanda/pytorch-arcface-gem-pooling-starter

GeM Pooling 

from https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/blob/master/src/modeling/metric_learning.py



ArcFace 


Comments 

Q. What is 'n_accumulate' in CONFIG?

A. This is for gradient accumulation. In this notebook, it is set to 1 so it makes no difference but in cases of using big models, batch size needs to be reduced(eg. 2) which leads to noisy gradients. So in this case we can accumulate the loss for some batches(eg. 4) and then do a backward pass. This increases our effective batch size to 2 * 4 = 8

<img width="522" alt="image" src="https://user-images.githubusercontent.com/48637189/159489407-bb51e510-ba80-4815-a6f3-a58a84eba795.png">

Q. ãªã‚“ã§K-Foldã§è‡ªå‹•ã®ã‚„ã¤ã‚’ä½¿ã‚ãªã„ã®ã‹ï¼Ÿ

A. ä»Šå›ã®ã‚³ãƒ³ãƒšãªã‚‰æ™‚é–“çš„ã«ä½™è£•ãŒã‚ã‚‹ãŒã€æ™®é€šã¯ä½™è£•ãŒãªã„ãŸã‚manualã§æ“ä½œã—ãŸã‚‚ã®ã‚’ä½¿ç”¨ã™ã‚‹ã€‚




