{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 🐋🐬 PyTorch ⚡ BackFin ConvNeXt ArcFace\n\nLet's train [`timm`](https://github.com/rwightman/pytorch-image-models) models with [PyTorch Lightning](https://www.pytorchlightning.ai/)!\n\n## Sources\n- [[Pytorch] ArcFace + GeM Pooling Starter](https://www.kaggle.com/debarshichanda/pytorch-arcface-gem-pooling-starter)\n- [FAISS Pytorch Inference](https://www.kaggle.com/debarshichanda/faiss-pytorch-inference)\n- [backfintfrecrods](https://www.kaggle.com/datasets/jpbremer/backfintfrecords) dataset\n\n## Nice Lightning `Trainer` Flags to try\n- Run a learning rate finder algorithm: `auto_lr_find=True`\n- Automatically try to find the largest batch size that fits into memory: `auto_scale_batch_size=True`\n- Quickly check whether everything runs fine: `fast_dev_run=True`\n- Train on multiple GPUs: `gpus=2` (if you use multiple GPUs, also set `accelerator=ddp`)\n- Train with half precision: `precision=16`\n- Use Stochastic Weight Averaging: `stochastic_weight_avg=True`\n\n## Public LB scores\n- V02: 0.378 (`image_size=256`, `\"tf_efficientnet_b2\"`, `batch_size=128`, `learning_rate=3e-4`)\n- V10: 0.439 (`image_size=512`, `\"tf_efficientnet_b0\"`, `batch_size=64`, `learning_rate=3e-4`)\n- V12: 0.498 (`image_size=512`, `\"tf_efficientnet_b2\"`, `batch_size=32`, `learning_rate=3e-4`)\n- V14: 0.567 (`image_size=512`, `\"tf_efficientnet_b4\"`, `batch_size=16`, `learning_rate=3e-4`)\n- V21: 0.656 (backfin cropped data, `image_size=384`, `\"tf_efficientnet_b4\"`, `batch_size=32`, `learning_rate=3e-4`, `scheduler=OneCycleLR`)\n- V22: 0.701 (backfin cropped data, `image_size=384`, `\"convnext_small\"`, `batch_size=32`, `learning_rate=3e-4`, `scheduler=OneCycleLR`)","metadata":{}},{"cell_type":"markdown","source":"# Installations (timm + FAISS)","metadata":{}},{"cell_type":"code","source":"pip install timm faiss-gpu","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:36.942595Z","iopub.execute_input":"2022-04-16T17:26:36.942909Z","iopub.status.idle":"2022-04-16T17:26:51.713415Z","shell.execute_reply.started":"2022-04-16T17:26:36.942829Z","shell.execute_reply":"2022-04-16T17:26:51.712469Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting timm\n  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n     |████████████████████████████████| 431 kB 776 kB/s            \n\u001b[?25hCollecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n     |████████████████████████████████| 85.5 MB 37.3 MB/s            \n\u001b[?25hRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm) (1.9.1)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.10.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (4.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.20.3)\nRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (8.2.0)\nInstalling collected packages: timm, faiss-gpu\nSuccessfully installed faiss-gpu-1.7.2 timm-0.5.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import math\nfrom typing import Callable\nfrom typing import Dict\nfrom typing import Optional\nfrom typing import Tuple\nfrom pathlib import Path\n\nimport faiss\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport timm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom PIL import Image\nfrom pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\nfrom timm.data.transforms_factory import create_transform\nfrom timm.optim import create_optimizer_v2\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import normalize\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-16T17:26:51.715790Z","iopub.execute_input":"2022-04-16T17:26:51.716136Z","iopub.status.idle":"2022-04-16T17:26:56.482802Z","shell.execute_reply.started":"2022-04-16T17:26:51.716078Z","shell.execute_reply":"2022-04-16T17:26:56.482050Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Paths & Settings","metadata":{}},{"cell_type":"code","source":"INPUT_DIR = Path(\"..\") / \"input\"\nOUTPUT_DIR = Path(\"/\") / \"kaggle\" / \"working\"\n\n# change to 4 channels dataset\nDATA_ROOT_DIR = INPUT_DIR / \"convert-backfintfrecords\" / \"happy-whale-and-dolphin-backfin\"\nTRAIN_DIR = DATA_ROOT_DIR / \"train_images\"\nTEST_DIR = DATA_ROOT_DIR / \"test_images\"\nTRAIN_CSV_PATH = DATA_ROOT_DIR / \"train.csv\"\nSAMPLE_SUBMISSION_CSV_PATH = DATA_ROOT_DIR / \"sample_submission.csv\"\nPUBLIC_SUBMISSION_CSV_PATH = INPUT_DIR / \"0-720-eff-b5-640-rotate\" / \"submission.csv\"\nIDS_WITHOUT_BACKFIN_PATH = INPUT_DIR / \"ids-without-backfin\" / \"ids_without_backfin.npy\"\n\nN_SPLITS = 5\n\nENCODER_CLASSES_PATH = OUTPUT_DIR / \"encoder_classes.npy\"\nTEST_CSV_PATH = OUTPUT_DIR / \"test.csv\"\nTRAIN_CSV_ENCODED_FOLDED_PATH = OUTPUT_DIR / \"train_encoded_folded.csv\"\nCHECKPOINTS_DIR = OUTPUT_DIR / \"checkpoints\"\nSUBMISSION_CSV_PATH = OUTPUT_DIR / \"submission.csv\"\n\nDEBUG = False","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:56.484504Z","iopub.execute_input":"2022-04-16T17:26:56.484767Z","iopub.status.idle":"2022-04-16T17:26:56.493831Z","shell.execute_reply.started":"2022-04-16T17:26:56.484732Z","shell.execute_reply":"2022-04-16T17:26:56.493161Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Prepare DataFrames","metadata":{}},{"cell_type":"code","source":"def get_image_path(id: str, dir: Path) -> str:\n    return f\"{dir / id}\"","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:56.496842Z","iopub.execute_input":"2022-04-16T17:26:56.497944Z","iopub.status.idle":"2022-04-16T17:26:56.503094Z","shell.execute_reply.started":"2022-04-16T17:26:56.497913Z","shell.execute_reply":"2022-04-16T17:26:56.502344Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Train DataFrame","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(TRAIN_CSV_PATH)\n\ntrain_df[\"image_path\"] = train_df[\"image\"].apply(get_image_path, dir=TRAIN_DIR)\n\nencoder = LabelEncoder()\ntrain_df[\"individual_id\"] = encoder.fit_transform(train_df[\"individual_id\"])\nnp.save(ENCODER_CLASSES_PATH, encoder.classes_)\n\nskf = StratifiedKFold(n_splits=N_SPLITS)\nfor fold, (_, val_) in enumerate(skf.split(X=train_df, y=train_df.individual_id)):\n    train_df.loc[val_, \"kfold\"] = fold\n    \ntrain_df.to_csv(TRAIN_CSV_ENCODED_FOLDED_PATH, index=False)\n    \ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:56.504356Z","iopub.execute_input":"2022-04-16T17:26:56.504905Z","iopub.status.idle":"2022-04-16T17:26:57.590636Z","shell.execute_reply.started":"2022-04-16T17:26:56.504869Z","shell.execute_reply":"2022-04-16T17:26:57.589916Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n  UserWarning,\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                image             species  individual_id  \\\n0  00021adfb725ed.jpg  melon_headed_whale          10938   \n1  000562241d384d.jpg      humpback_whale           1453   \n2  0007c33415ce37.jpg  false_killer_whale           5158   \n3  0007d9bca26a99.jpg  bottlenose_dolphin           4031   \n4  00087baf5cef7a.jpg      humpback_whale           7726   \n\n                                          image_path  kfold  \n0  ../input/convert-backfintfrecords/happy-whale-...    0.0  \n1  ../input/convert-backfintfrecords/happy-whale-...    1.0  \n2  ../input/convert-backfintfrecords/happy-whale-...    0.0  \n3  ../input/convert-backfintfrecords/happy-whale-...    0.0  \n4  ../input/convert-backfintfrecords/happy-whale-...    0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>species</th>\n      <th>individual_id</th>\n      <th>image_path</th>\n      <th>kfold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00021adfb725ed.jpg</td>\n      <td>melon_headed_whale</td>\n      <td>10938</td>\n      <td>../input/convert-backfintfrecords/happy-whale-...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000562241d384d.jpg</td>\n      <td>humpback_whale</td>\n      <td>1453</td>\n      <td>../input/convert-backfintfrecords/happy-whale-...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0007c33415ce37.jpg</td>\n      <td>false_killer_whale</td>\n      <td>5158</td>\n      <td>../input/convert-backfintfrecords/happy-whale-...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0007d9bca26a99.jpg</td>\n      <td>bottlenose_dolphin</td>\n      <td>4031</td>\n      <td>../input/convert-backfintfrecords/happy-whale-...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00087baf5cef7a.jpg</td>\n      <td>humpback_whale</td>\n      <td>7726</td>\n      <td>../input/convert-backfintfrecords/happy-whale-...</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Test DataFrame","metadata":{}},{"cell_type":"code","source":"# Use sample submission csv as template\ntest_df = pd.read_csv(SAMPLE_SUBMISSION_CSV_PATH)\ntest_df[\"image_path\"] = test_df[\"image\"].apply(get_image_path, dir=TEST_DIR)\n\ntest_df.drop(columns=[\"predictions\"], inplace=True)\n\n# Dummy id\ntest_df[\"individual_id\"] = 0\n\ntest_df.to_csv(TEST_CSV_PATH, index=False)\n\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:57.592103Z","iopub.execute_input":"2022-04-16T17:26:57.592361Z","iopub.status.idle":"2022-04-16T17:26:57.985930Z","shell.execute_reply.started":"2022-04-16T17:26:57.592317Z","shell.execute_reply":"2022-04-16T17:26:57.985259Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                image                                         image_path  \\\n0  000110707af0ba.jpg  ../input/convert-backfintfrecords/happy-whale-...   \n1  0006287ec424cb.jpg  ../input/convert-backfintfrecords/happy-whale-...   \n2  000809ecb2ccad.jpg  ../input/convert-backfintfrecords/happy-whale-...   \n3  00098d1376dab2.jpg  ../input/convert-backfintfrecords/happy-whale-...   \n4  000b8d89c738bd.jpg  ../input/convert-backfintfrecords/happy-whale-...   \n\n   individual_id  \n0              0  \n1              0  \n2              0  \n3              0  \n4              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>image_path</th>\n      <th>individual_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000110707af0ba.jpg</td>\n      <td>../input/convert-backfintfrecords/happy-whale-...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0006287ec424cb.jpg</td>\n      <td>../input/convert-backfintfrecords/happy-whale-...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000809ecb2ccad.jpg</td>\n      <td>../input/convert-backfintfrecords/happy-whale-...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00098d1376dab2.jpg</td>\n      <td>../input/convert-backfintfrecords/happy-whale-...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000b8d89c738bd.jpg</td>\n      <td>../input/convert-backfintfrecords/happy-whale-...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"# import cv2\n# path=\"../input/convert-backfintfrecords/happy-whale-and-dolphin-backfin/test_images/000b8d89c738bd.jpg\"\n# image = cv2.imread(path)\n# image.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:57.987238Z","iopub.execute_input":"2022-04-16T17:26:57.987646Z","iopub.status.idle":"2022-04-16T17:26:57.991145Z","shell.execute_reply.started":"2022-04-16T17:26:57.987608Z","shell.execute_reply":"2022-04-16T17:26:57.990387Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class HappyWhaleDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, transform: Optional[Callable] = None):\n        self.df = df\n        self.transform = transform\n\n        self.image_names = self.df[\"image\"].values\n        self.image_paths = self.df[\"image_path\"].values\n        self.targets = self.df[\"individual_id\"].values\n\n    def __getitem__(self, index: int) -> Dict[str, torch.Tensor]:\n        image_name = self.image_names[index]\n\n        image_path = self.image_paths[index]\n\n        image = Image.open(image_path)\n        \n        if self.transform:\n            image = self.transform(image)\n\n        target = self.targets[index]\n        target = torch.tensor(target, dtype=torch.long)\n\n        return {\"image_name\": image_name, \"image\": image, \"target\": target}\n\n    def __len__(self) -> int:\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:57.992440Z","iopub.execute_input":"2022-04-16T17:26:57.992828Z","iopub.status.idle":"2022-04-16T17:26:58.002509Z","shell.execute_reply.started":"2022-04-16T17:26:57.992791Z","shell.execute_reply":"2022-04-16T17:26:58.001674Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Lightning DataModule","metadata":{}},{"cell_type":"code","source":"class LitDataModule(pl.LightningDataModule):\n    def __init__(\n        self,\n        train_csv_encoded_folded: str,\n        test_csv: str,\n        val_fold: float,\n        image_size: int,\n        batch_size: int,\n        num_workers: int,\n    ):\n        super().__init__()\n\n        self.save_hyperparameters()\n\n        self.train_df = pd.read_csv(train_csv_encoded_folded)\n        self.test_df = pd.read_csv(test_csv)\n        \n        self.transform = create_transform(\n            input_size=(self.hparams.image_size, self.hparams.image_size),\n            crop_pct=1.0,\n        )\n        \n    def setup(self, stage: Optional[str] = None):\n        if stage == \"fit\" or stage is None:\n            # Split train df using fold\n            train_df = self.train_df[self.train_df.kfold != self.hparams.val_fold].reset_index(drop=True)\n            val_df = self.train_df[self.train_df.kfold == self.hparams.val_fold].reset_index(drop=True)\n\n            self.train_dataset = HappyWhaleDataset(train_df, transform=self.transform)\n            self.val_dataset = HappyWhaleDataset(val_df, transform=self.transform)\n\n        if stage == \"test\" or stage is None:\n            self.test_dataset = HappyWhaleDataset(self.test_df, transform=self.transform)\n\n    def train_dataloader(self) -> DataLoader:\n        return self._dataloader(self.train_dataset, train=True)\n\n    def val_dataloader(self) -> DataLoader:\n        return self._dataloader(self.val_dataset)\n\n    def test_dataloader(self) -> DataLoader:\n        return self._dataloader(self.test_dataset)\n\n    def _dataloader(self, dataset: HappyWhaleDataset, train: bool = False) -> DataLoader:\n        return DataLoader(\n            dataset,\n            batch_size=self.hparams.batch_size,\n            shuffle=train,\n            num_workers=self.hparams.num_workers,\n            pin_memory=True,\n            drop_last=train,\n        )","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:58.003843Z","iopub.execute_input":"2022-04-16T17:26:58.004108Z","iopub.status.idle":"2022-04-16T17:26:58.016645Z","shell.execute_reply.started":"2022-04-16T17:26:58.004073Z","shell.execute_reply":"2022-04-16T17:26:58.015586Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# ArcMargin","metadata":{}},{"cell_type":"code","source":"# From https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/blob/master/src/modeling/metric_learning.py\n# Added type annotations, device, and 16bit support\nclass ArcMarginProduct(nn.Module):\n    r\"\"\"Implement of large margin arc distance: :\n    Args:\n        in_features: size of each input sample\n        out_features: size of each output sample\n        s: norm of input feature\n        m: margin\n        cos(theta + m)\n    \"\"\"\n\n    def __init__(\n        self,\n        in_features: int,\n        out_features: int,\n        s: float,\n        m: float,\n        easy_margin: bool,\n        ls_eps: float,\n    ):\n        super(ArcMarginProduct, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps  # label smoothing\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n        self.easy_margin = easy_margin\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = math.cos(math.pi - m)\n        self.mm = math.sin(math.pi - m) * m\n\n    def forward(self, input: torch.Tensor, label: torch.Tensor, device: str = \"cuda\") -> torch.Tensor:\n        # --------------------------- cos(theta) & phi(theta) ---------------------\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        # Enable 16 bit precision\n        cosine = cosine.to(torch.float32)\n\n        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n        # --------------------------- convert label to one-hot ---------------------\n        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n        one_hot = torch.zeros(cosine.size(), device=device)\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n        # -------------torch.where(out_i = {x_i if condition_i else y_i) ------------\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:58.020171Z","iopub.execute_input":"2022-04-16T17:26:58.021099Z","iopub.status.idle":"2022-04-16T17:26:58.035416Z","shell.execute_reply.started":"2022-04-16T17:26:58.021060Z","shell.execute_reply":"2022-04-16T17:26:58.034651Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Lightning Module","metadata":{}},{"cell_type":"code","source":"class LitModule(pl.LightningModule):\n    def __init__(\n        self,\n        model_name: str,\n        pretrained: bool,\n        drop_rate: float,\n        embedding_size: int,\n        num_classes: int,\n        arc_s: float,\n        arc_m: float,\n        arc_easy_margin: bool,\n        arc_ls_eps: float,\n        optimizer: str,\n        learning_rate: float,\n        weight_decay: float,\n        len_train_dl: int,\n        epochs:int\n    ):\n        super().__init__()\n\n        self.save_hyperparameters()\n\n        self.model = timm.create_model(model_name, pretrained=pretrained, drop_rate=drop_rate)\n        self.embedding = nn.Linear(self.model.get_classifier().in_features, embedding_size)\n        self.model.reset_classifier(num_classes=0, global_pool=\"avg\")\n\n        self.arc = ArcMarginProduct(\n            in_features=embedding_size,\n            out_features=num_classes,\n            s=arc_s,\n            m=arc_m,\n            easy_margin=arc_easy_margin,\n            ls_eps=arc_ls_eps,\n        )\n\n        self.loss_fn = F.cross_entropy\n\n    def forward(self, images: torch.Tensor) -> torch.Tensor:\n        features = self.model(images)\n        embeddings = self.embedding(features)\n\n        return embeddings\n\n    def configure_optimizers(self):\n        optimizer = create_optimizer_v2(\n            self.parameters(),\n            opt=self.hparams.optimizer,\n            lr=self.hparams.learning_rate,\n            weight_decay=self.hparams.weight_decay,\n        )\n        \n        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n            optimizer,\n            self.hparams.learning_rate,\n            steps_per_epoch=self.hparams.len_train_dl,\n            epochs=self.hparams.epochs,\n        )\n        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n\n        return [optimizer], [scheduler]\n\n    def training_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> torch.Tensor:\n        return self._step(batch, \"train\")\n\n    def validation_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> torch.Tensor:\n        return self._step(batch, \"val\")\n\n    def _step(self, batch: Dict[str, torch.Tensor], step: str) -> torch.Tensor:\n        images, targets = batch[\"image\"], batch[\"target\"]\n\n        embeddings = self(images)\n        outputs = self.arc(embeddings, targets, self.device)\n\n        loss = self.loss_fn(outputs, targets)\n        \n        self.log(f\"{step}_loss\", loss)\n\n        return loss","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:58.036839Z","iopub.execute_input":"2022-04-16T17:26:58.037191Z","iopub.status.idle":"2022-04-16T17:26:58.053329Z","shell.execute_reply.started":"2022-04-16T17:26:58.037155Z","shell.execute_reply":"2022-04-16T17:26:58.052514Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"class Conv2dSame(nn.Conv2d):\n    \"\"\" Tensorflow like 'SAME' convolution wrapper for 2D convolutions\n    \"\"\"\n\n    # pylint: disable=unused-argument\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n                 padding=0, dilation=1, groups=1, bias=True):\n        super(Conv2dSame, self).__init__(\n            in_channels, out_channels, kernel_size, stride, 0, dilation, groups, bias)\n\n    def forward(self, x):\n        return conv2d_same(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:58.054601Z","iopub.execute_input":"2022-04-16T17:26:58.054909Z","iopub.status.idle":"2022-04-16T17:26:58.064721Z","shell.execute_reply.started":"2022-04-16T17:26:58.054874Z","shell.execute_reply":"2022-04-16T17:26:58.063896Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_csv_encoded_folded: str = str(TRAIN_CSV_ENCODED_FOLDED_PATH)\ntest_csv: str = str(TEST_CSV_PATH)\nval_fold: float = 0.0\nimage_size: int = 256\nbatch_size: int = 64\nnum_workers: int = 2\nmodel_name: str = \"tf_efficientnet_b5\"\n# model_name: str = \"convnext_base_384_in22ft1k\"\npretrained: bool = True\ndrop_rate: float = 0.0\nembedding_size: int = 512\nnum_classes: int = 15587\narc_s: float = 30.0\narc_m: float = 0.5\narc_easy_margin: bool = False\narc_ls_eps: float = 0.0\noptimizer: str = \"adam\"\nlearning_rate: float = 3e-4\nweight_decay: float = 1e-6\ncheckpoints_dir: str = str(CHECKPOINTS_DIR)\naccumulate_grad_batches: int = 1\nauto_lr_find: bool = False\nauto_scale_batch_size: bool = False\nfast_dev_run: bool = False\ngpus: int = 1\nmax_epochs: int = 10\nprecision: int = 16\nstochastic_weight_avg: bool = True\n        \npl.seed_everything(42)\n\ndatamodule = LitDataModule(\n    train_csv_encoded_folded=train_csv_encoded_folded,\n    test_csv=test_csv,\n    val_fold=val_fold,\n    image_size=image_size,\n    batch_size=batch_size,\n    num_workers=num_workers,\n)\n\ndatamodule.setup()\nlen_train_dl = len(datamodule.train_dataloader())\n\nmodule = LitModule(\n    model_name=model_name,\n    pretrained=pretrained,\n    drop_rate=drop_rate,\n    embedding_size=embedding_size,\n    num_classes=num_classes,\n    arc_s=arc_s,\n    arc_m=arc_m,\n    arc_easy_margin=arc_easy_margin,\n    arc_ls_eps=arc_ls_eps,\n    optimizer=optimizer,\n    learning_rate=learning_rate,\n    weight_decay=weight_decay,\n    len_train_dl=len_train_dl,\n    epochs=max_epochs\n)\n\nmodel_checkpoint = ModelCheckpoint(\n    checkpoints_dir,\n    filename=f\"{model_name}_{image_size}\",\n    monitor=\"val_loss\",\n)\n\ntrainer = pl.Trainer(\n    accumulate_grad_batches=accumulate_grad_batches,\n    auto_lr_find=auto_lr_find,\n    auto_scale_batch_size=auto_scale_batch_size,\n    benchmark=True,\n    callbacks=[model_checkpoint],\n    deterministic=True,\n    fast_dev_run=fast_dev_run,\n    gpus=gpus,\n    max_epochs=2 if DEBUG else max_epochs,\n    precision=precision,\n    stochastic_weight_avg=stochastic_weight_avg,\n    limit_train_batches=0.1 if DEBUG else 1.0,\n    limit_val_batches=0.1 if DEBUG else 1.0,\n)\n\n# trainer.tune(module, datamodule=datamodule)\n\n# trainer.fit(module, datamodule=datamodule)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:58.066221Z","iopub.execute_input":"2022-04-16T17:26:58.066429Z","iopub.status.idle":"2022-04-16T17:27:03.899550Z","shell.execute_reply.started":"2022-04-16T17:26:58.066404Z","shell.execute_reply":"2022-04-16T17:27:03.897897Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b5_ra-9a3e5369.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b5_ra-9a3e5369.pth\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:59: LightningDeprecationWarning: Setting `Trainer(stochastic_weight_avg=True)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.stochastic_weight_avg.StochasticWeightAveraging` directly to the Trainer's `callbacks` argument instead.\n  \"Setting `Trainer(stochastic_weight_avg=True)` is deprecated in v1.5 and will be removed in v1.7.\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# module._modules['model'].stem[0]=nn.Conv2d(4, 128, kernel_size=(4, 4), stride=(4, 4))\n# module._modules['model'].conv_stem=Conv2dSame(4, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n\nmodule._modules","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:27:03.900840Z","iopub.execute_input":"2022-04-16T17:27:03.902167Z","iopub.status.idle":"2022-04-16T17:27:03.917778Z","shell.execute_reply.started":"2022-04-16T17:27:03.902126Z","shell.execute_reply":"2022-04-16T17:27:03.916918Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"OrderedDict([('model',\n              EfficientNet(\n                (conv_stem): Conv2dSame(3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False)\n                (bn1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                (act1): SiLU(inplace=True)\n                (blocks): Sequential(\n                  (0): Sequential(\n                    (0): DepthwiseSeparableConv(\n                      (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n                      (bn1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): Identity()\n                    )\n                    (1): DepthwiseSeparableConv(\n                      (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n                      (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): Identity()\n                    )\n                    (2): DepthwiseSeparableConv(\n                      (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n                      (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): Identity()\n                    )\n                  )\n                  (1): Sequential(\n                    (0): InvertedResidual(\n                      (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2dSame(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n                      (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (1): InvertedResidual(\n                      (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n                      (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (2): InvertedResidual(\n                      (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n                      (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (3): InvertedResidual(\n                      (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n                      (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (4): InvertedResidual(\n                      (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n                      (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                  )\n                  (2): Sequential(\n                    (0): InvertedResidual(\n                      (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2dSame(240, 240, kernel_size=(5, 5), stride=(2, 2), groups=240, bias=False)\n                      (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (1): InvertedResidual(\n                      (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n                      (bn2): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (2): InvertedResidual(\n                      (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n                      (bn2): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (3): InvertedResidual(\n                      (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n                      (bn2): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (4): InvertedResidual(\n                      (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n                      (bn2): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                  )\n                  (3): Sequential(\n                    (0): InvertedResidual(\n                      (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2dSame(384, 384, kernel_size=(3, 3), stride=(2, 2), groups=384, bias=False)\n                      (bn2): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (1): InvertedResidual(\n                      (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n                      (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (2): InvertedResidual(\n                      (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n                      (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (3): InvertedResidual(\n                      (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n                      (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (4): InvertedResidual(\n                      (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n                      (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (5): InvertedResidual(\n                      (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n                      (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (6): InvertedResidual(\n                      (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n                      (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                  )\n                  (4): Sequential(\n                    (0): InvertedResidual(\n                      (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n                      (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(768, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (1): InvertedResidual(\n                      (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n                      (bn2): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (2): InvertedResidual(\n                      (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n                      (bn2): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (3): InvertedResidual(\n                      (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n                      (bn2): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (4): InvertedResidual(\n                      (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n                      (bn2): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (5): InvertedResidual(\n                      (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n                      (bn2): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (6): InvertedResidual(\n                      (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n                      (bn2): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                  )\n                  (5): Sequential(\n                    (0): InvertedResidual(\n                      (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2dSame(1056, 1056, kernel_size=(5, 5), stride=(2, 2), groups=1056, bias=False)\n                      (bn2): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (1): InvertedResidual(\n                      (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n                      (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (2): InvertedResidual(\n                      (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n                      (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (3): InvertedResidual(\n                      (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n                      (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (4): InvertedResidual(\n                      (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n                      (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (5): InvertedResidual(\n                      (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n                      (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (6): InvertedResidual(\n                      (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n                      (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (7): InvertedResidual(\n                      (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n                      (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (8): InvertedResidual(\n                      (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n                      (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                  )\n                  (6): Sequential(\n                    (0): InvertedResidual(\n                      (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n                      (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (1): InvertedResidual(\n                      (conv_pw): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n                      (bn2): BatchNorm2d(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                    (2): InvertedResidual(\n                      (conv_pw): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn1): BatchNorm2d(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act1): SiLU(inplace=True)\n                      (conv_dw): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n                      (bn2): BatchNorm2d(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                      (act2): SiLU(inplace=True)\n                      (se): SqueezeExcite(\n                        (conv_reduce): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n                        (act1): SiLU(inplace=True)\n                        (conv_expand): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n                        (gate): Sigmoid()\n                      )\n                      (conv_pwl): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                      (bn3): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                    )\n                  )\n                )\n                (conv_head): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn2): BatchNorm2d(2048, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n                (act2): SiLU(inplace=True)\n                (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n                (classifier): Identity()\n              )),\n             ('embedding',\n              Linear(in_features=2048, out_features=512, bias=True)),\n             ('arc', ArcMarginProduct())])"},"metadata":{}}]},{"cell_type":"code","source":"def train(\n    train_csv_encoded_folded: str = str(TRAIN_CSV_ENCODED_FOLDED_PATH),\n    test_csv: str = str(TEST_CSV_PATH),\n    val_fold: float = 0.0,\n    image_size: int = 256,\n    batch_size: int = 64,\n    num_workers: int = 2,\n    model_name: str = \"tf_efficientnet_b0\",\n    pretrained: bool = True,\n    drop_rate: float = 0.0,\n    embedding_size: int = 512,\n    num_classes: int = 15587,\n    arc_s: float = 30.0,\n    arc_m: float = 0.5,\n    arc_easy_margin: bool = False,\n    arc_ls_eps: float = 0.0,\n    optimizer: str = \"adam\",\n    learning_rate: float = 3e-4,\n    weight_decay: float = 1e-6,\n    checkpoints_dir: str = str(CHECKPOINTS_DIR),\n    accumulate_grad_batches: int = 1,\n    auto_lr_find: bool = False,\n    auto_scale_batch_size: bool = False,\n    fast_dev_run: bool = False,\n    gpus: int = 1,\n    max_epochs: int = 10,\n    precision: int = 16,\n    stochastic_weight_avg: bool = True,\n):\n    pl.seed_everything(42)\n\n    datamodule = LitDataModule(\n        train_csv_encoded_folded=train_csv_encoded_folded,\n        test_csv=test_csv,\n        val_fold=val_fold,\n        image_size=image_size,\n        batch_size=batch_size,\n        num_workers=num_workers,\n    )\n    \n    datamodule.setup()\n    len_train_dl = len(datamodule.train_dataloader())\n\n    module = LitModule(\n        model_name=model_name,\n        pretrained=pretrained,\n        drop_rate=drop_rate,\n        embedding_size=embedding_size,\n        num_classes=num_classes,\n        arc_s=arc_s,\n        arc_m=arc_m,\n        arc_easy_margin=arc_easy_margin,\n        arc_ls_eps=arc_ls_eps,\n        optimizer=optimizer,\n        learning_rate=learning_rate,\n        weight_decay=weight_decay,\n        len_train_dl=len_train_dl,\n        epochs=max_epochs\n    )\n    \n    # 3 channels to 4 channels\n    if model_name == \"convnext_base_384_in22ft1k\":\n        module._modules['model'].stem[0]=nn.Conv2d(4, 128, kernel_size=(4, 4), stride=(4, 4))\n    elif model_name in [\"tf_efficientnet_b0\",\"tf_efficientnet_b5\",\"tf_efficientnet_b6\",\"tf_efficientnet_b7\"]:\n        module._modules['model'].conv_stem=Conv2dSame(4, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n    \n    model_checkpoint = ModelCheckpoint(\n        checkpoints_dir,\n        filename=f\"{model_name}_{image_size}\",\n        monitor=\"val_loss\",\n    )\n        \n    trainer = pl.Trainer(\n        accumulate_grad_batches=accumulate_grad_batches,\n        auto_lr_find=auto_lr_find,\n        auto_scale_batch_size=auto_scale_batch_size,\n        benchmark=True,\n        callbacks=[model_checkpoint],\n        deterministic=True,\n        fast_dev_run=fast_dev_run,\n        gpus=gpus,\n        max_epochs=2 if DEBUG else max_epochs,\n        precision=precision,\n        stochastic_weight_avg=stochastic_weight_avg,\n        limit_train_batches=0.1 if DEBUG else 1.0,\n        limit_val_batches=0.1 if DEBUG else 1.0,\n    )\n\n    trainer.tune(module, datamodule=datamodule)\n\n    trainer.fit(module, datamodule=datamodule)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:41:45.840644Z","iopub.execute_input":"2022-04-16T14:41:45.841126Z","iopub.status.idle":"2022-04-16T14:41:45.857649Z","shell.execute_reply.started":"2022-04-16T14:41:45.841091Z","shell.execute_reply":"2022-04-16T14:41:45.856902Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model_name = \"convnext_base_384_in22ft1k\"\nimage_size = 384\nbatch_size = 16\n\ntrain(model_name=model_name,\n      image_size=image_size,\n      batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:41:47.725977Z","iopub.execute_input":"2022-04-16T14:41:47.726239Z","iopub.status.idle":"2022-04-16T14:42:14.809649Z","shell.execute_reply.started":"2022-04-16T14:41:47.726210Z","shell.execute_reply":"2022-04-16T14:42:14.808058Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Downloading: \"https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_1k_384.pth\" to /root/.cache/torch/hub/checkpoints/convnext_base_22k_1k_384.pth\n/opt/conda/lib/python3.7/site-packages/pytorch_lightning/core/datamodule.py:470: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n  f\"DataModule.{name} has already been called, so it will not be called again. \"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation sanity check: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"973156621e4a4453aea732c1b1540aa0"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/894648553.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m train(model_name=model_name,\n\u001b[1;32m      6\u001b[0m       \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       batch_size=batch_size)\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_33/1283210305.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_csv_encoded_folded, test_csv, val_fold, image_size, batch_size, num_workers, model_name, pretrained, drop_rate, embedding_size, num_classes, arc_s, arc_m, arc_easy_margin, arc_ls_eps, optimizer, learning_rate, weight_decay, checkpoints_dir, accumulate_grad_batches, auto_lr_find, auto_scale_batch_size, fast_dev_run, gpus, max_epochs, precision, stochastic_weight_avg)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatamodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatamodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0mtrain_dataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         self._call_and_handle_interrupt(\n\u001b[0;32m--> 741\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m         )\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \"\"\"\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;31m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;31m# TODO: ckpt_path only in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt_path\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1277\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1309\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1311\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0;31m# enable train mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_sanity_check_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mdl_max_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataloader_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mdl_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_max_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_dataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# store batch level output per dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher, dataloader_idx, dl_max_batches, num_dataloaders)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluation_step_and_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36m_evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, step_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \"\"\"\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_33/1525931547.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_33/1525931547.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, batch, step)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_33/1525931547.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/timm/models/convnext.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/timm/models/convnext.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 4, 4, 4], expected input[16, 3, 384, 384] to have 4 channels, but got 3 channels instead"],"ename":"RuntimeError","evalue":"Given groups=1, weight of size [128, 4, 4, 4], expected input[16, 3, 384, 384] to have 4 channels, but got 3 channels instead","output_type":"error"}]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"def load_eval_module(checkpoint_path: str, device: torch.device) -> LitModule:\n    module = LitModule.load_from_checkpoint(checkpoint_path)\n    module.to(device)\n    module.eval()\n\n    return module\n\ndef load_dataloaders(\n    train_csv_encoded_folded: str,\n    test_csv: str,\n    val_fold: float,\n    image_size: int,\n    batch_size: int,\n    num_workers: int,\n) -> Tuple[DataLoader, DataLoader, DataLoader]:\n\n    datamodule = LitDataModule(\n        train_csv_encoded_folded=train_csv_encoded_folded,\n        test_csv=test_csv,\n        val_fold=val_fold,\n        image_size=image_size,\n        batch_size=batch_size,\n        num_workers=num_workers,\n    )\n\n    datamodule.setup()\n\n    train_dl = datamodule.train_dataloader()\n    val_dl = datamodule.val_dataloader()\n    test_dl = datamodule.test_dataloader()\n\n    return train_dl, val_dl, test_dl\n\n\ndef load_encoder() -> LabelEncoder:\n    encoder = LabelEncoder()\n    encoder.classes_ = np.load(ENCODER_CLASSES_PATH, allow_pickle=True)\n\n    return encoder\n\n\n@torch.inference_mode()\ndef get_embeddings(\n    module: pl.LightningModule, dataloader: DataLoader, encoder: LabelEncoder, stage: str\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n\n    all_image_names = []\n    all_embeddings = []\n    all_targets = []\n\n    for batch in tqdm(dataloader, desc=f\"Creating {stage} embeddings\"):\n        image_names = batch[\"image_name\"]\n        images = batch[\"image\"].to(module.device)\n        targets = batch[\"target\"].to(module.device)\n\n        embeddings = module(images)\n\n        all_image_names.append(image_names)\n        all_embeddings.append(embeddings.cpu().numpy())\n        all_targets.append(targets.cpu().numpy())\n        \n        if DEBUG:\n            break\n\n    all_image_names = np.concatenate(all_image_names)\n    all_embeddings = np.vstack(all_embeddings)\n    all_targets = np.concatenate(all_targets)\n\n    all_embeddings = normalize(all_embeddings, axis=1, norm=\"l2\")\n    all_targets = encoder.inverse_transform(all_targets)\n\n    return all_image_names, all_embeddings, all_targets\n\n\ndef create_and_search_index(embedding_size: int, train_embeddings: np.ndarray, val_embeddings: np.ndarray, k: int):\n    index = faiss.IndexFlatIP(embedding_size)\n    index.add(train_embeddings)\n    D, I = index.search(val_embeddings, k=k)  # noqa: E741\n\n    return D, I\n\n\ndef create_val_targets_df(\n    train_targets: np.ndarray, val_image_names: np.ndarray, val_targets: np.ndarray\n) -> pd.DataFrame:\n\n    allowed_targets = np.unique(train_targets)\n    val_targets_df = pd.DataFrame(np.stack([val_image_names, val_targets], axis=1), columns=[\"image\", \"target\"])\n    val_targets_df.loc[~val_targets_df.target.isin(allowed_targets), \"target\"] = \"new_individual\"\n\n    return val_targets_df\n\n\ndef create_distances_df(\n    image_names: np.ndarray, targets: np.ndarray, D: np.ndarray, I: np.ndarray, stage: str  # noqa: E741\n) -> pd.DataFrame:\n\n    distances_df = []\n    for i, image_name in tqdm(enumerate(image_names), desc=f\"Creating {stage}_df\"):\n        target = targets[I[i]]\n        distances = D[i]\n        subset_preds = pd.DataFrame(np.stack([target, distances], axis=1), columns=[\"target\", \"distances\"])\n        subset_preds[\"image\"] = image_name\n        distances_df.append(subset_preds)\n\n    distances_df = pd.concat(distances_df).reset_index(drop=True)\n    distances_df = distances_df.groupby([\"image\", \"target\"]).distances.max().reset_index()\n    distances_df = distances_df.sort_values(\"distances\", ascending=False).reset_index(drop=True)\n\n    return distances_df\n\n\ndef get_best_threshold(val_targets_df: pd.DataFrame, valid_df: pd.DataFrame) -> Tuple[float, float]:\n    best_th = 0\n    best_cv = 0\n    for th in [0.1 * x for x in range(11)]:\n        all_preds = get_predictions(valid_df, threshold=th)\n\n        cv = 0\n        for i, row in val_targets_df.iterrows():\n            target = row.target\n            preds = all_preds[row.image]\n            val_targets_df.loc[i, th] = map_per_image(target, preds)\n\n        cv = val_targets_df[th].mean()\n\n        print(f\"th={th} cv={cv}\")\n\n        if cv > best_cv:\n            best_th = th\n            best_cv = cv\n\n    print(f\"best_th={best_th}\")\n    print(f\"best_cv={best_cv}\")\n\n    # Adjustment: Since Public lb has nearly 10% 'new_individual' (Be Careful for private LB)\n    val_targets_df[\"is_new_individual\"] = val_targets_df.target == \"new_individual\"\n    val_scores = val_targets_df.groupby(\"is_new_individual\").mean().T\n    val_scores[\"adjusted_cv\"] = val_scores[True] * 0.1 + val_scores[False] * 0.9\n    best_th = val_scores[\"adjusted_cv\"].idxmax()\n    print(f\"best_th_adjusted={best_th}\")\n\n    return best_th, best_cv\n\n\ndef get_predictions(df: pd.DataFrame, threshold: float = 0.2):\n    sample_list = [\"938b7e931166\", \"5bf17305f073\", \"7593d2aee842\", \"7362d7a01d00\", \"956562ff2888\"]\n\n    predictions = {}\n    for i, row in tqdm(df.iterrows(), total=len(df), desc=f\"Creating predictions for threshold={threshold}\"):\n        if row.image in predictions:\n            if len(predictions[row.image]) == 5:\n                continue\n            predictions[row.image].append(row.target)\n        elif row.distances > threshold:\n            predictions[row.image] = [row.target, \"new_individual\"]\n        else:\n            predictions[row.image] = [\"new_individual\", row.target]\n\n    for x in tqdm(predictions):\n        if len(predictions[x]) < 5:\n            remaining = [y for y in sample_list if y not in predictions]\n            predictions[x] = predictions[x] + remaining\n            predictions[x] = predictions[x][:5]\n\n    return predictions\n\n\n# TODO: add types\ndef map_per_image(label, predictions):\n    \"\"\"Computes the precision score of one image.\n\n    Parameters\n    ----------\n    label : string\n            The true label of the image\n    predictions : list\n            A list of predicted elements (order does matter, 5 predictions allowed per image)\n\n    Returns\n    -------\n    score : double\n    \"\"\"\n    try:\n        return 1 / (predictions[:5].index(label) + 1)\n    except ValueError:\n        return 0.0\n\n\ndef create_predictions_df(test_df: pd.DataFrame, best_th: float) -> pd.DataFrame:\n    predictions = get_predictions(test_df, best_th)\n\n    predictions = pd.Series(predictions).reset_index()\n    predictions.columns = [\"image\", \"predictions\"]\n    predictions[\"predictions\"] = predictions[\"predictions\"].apply(lambda x: \" \".join(x))\n\n    return predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def infer(\n    checkpoint_path: str,\n    train_csv_encoded_folded: str = str(TRAIN_CSV_ENCODED_FOLDED_PATH),\n    test_csv: str = str(TEST_CSV_PATH),\n    val_fold: float = 0.0,\n    image_size: int = 256,\n    batch_size: int = 64,\n    num_workers: int = 2,\n    k: int = 50,\n):\n    module = load_eval_module(checkpoint_path, torch.device(\"cuda\"))\n\n    train_dl, val_dl, test_dl = load_dataloaders(\n        train_csv_encoded_folded=train_csv_encoded_folded,\n        test_csv=test_csv,\n        val_fold=val_fold,\n        image_size=image_size,\n        batch_size=batch_size,\n        num_workers=num_workers,\n    )\n\n    encoder = load_encoder()\n\n    train_image_names, train_embeddings, train_targets = get_embeddings(module, train_dl, encoder, stage=\"train\")\n    val_image_names, val_embeddings, val_targets = get_embeddings(module, val_dl, encoder, stage=\"val\")\n    test_image_names, test_embeddings, test_targets = get_embeddings(module, test_dl, encoder, stage=\"test\")\n\n    D, I = create_and_search_index(module.hparams.embedding_size, train_embeddings, val_embeddings, k)  # noqa: E741\n    print(\"Created index with train_embeddings\")\n\n    val_targets_df = create_val_targets_df(train_targets, val_image_names, val_targets)\n    print(f\"val_targets_df=\\n{val_targets_df.head()}\")\n\n    val_df = create_distances_df(val_image_names, train_targets, D, I, \"val\")\n    print(f\"val_df=\\n{val_df.head()}\")\n\n    best_th, best_cv = get_best_threshold(val_targets_df, val_df)\n    print(f\"val_targets_df=\\n{val_targets_df.describe()}\")\n\n    train_embeddings = np.concatenate([train_embeddings, val_embeddings])\n    train_targets = np.concatenate([train_targets, val_targets])\n    print(\"Updated train_embeddings and train_targets with val data\")\n\n    D, I = create_and_search_index(module.hparams.embedding_size, train_embeddings, test_embeddings, k)  # noqa: E741\n    print(\"Created index with train_embeddings\")\n\n    test_df = create_distances_df(test_image_names, train_targets, D, I, \"test\")\n    print(f\"test_df=\\n{test_df.head()}\")\n\n    predictions = create_predictions_df(test_df, best_th)\n    print(f\"predictions.head()={predictions.head()}\")\n    \n    # Fix missing predictions\n    # From https://www.kaggle.com/code/jpbremer/backfins-arcface-tpu-effnet/notebook\n    public_predictions = pd.read_csv(PUBLIC_SUBMISSION_CSV_PATH)\n    ids_without_backfin = np.load(IDS_WITHOUT_BACKFIN_PATH, allow_pickle=True)\n\n    ids2 = public_predictions[\"image\"][~public_predictions[\"image\"].isin(predictions[\"image\"])]\n\n    predictions = pd.concat(\n        [\n            predictions[~(predictions[\"image\"].isin(ids_without_backfin))],\n            public_predictions[public_predictions[\"image\"].isin(ids_without_backfin)],\n            public_predictions[public_predictions[\"image\"].isin(ids2)],\n        ]\n    )\n    predictions = predictions.drop_duplicates()\n\n    predictions.to_csv(SUBMISSION_CSV_PATH, index=False)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"infer(checkpoint_path=CHECKPOINTS_DIR / f\"{model_name}_{image_size}.ckpt\", image_size=image_size, batch_size=batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}